Fri Dec  6 11:23:01 EST 2019
guppy7
/h/laleh/PycharmProjects/Fairness/Nov28/CXP/3
  0%|          | 0/65 [00:00<?, ?it/s]Validation_df size: 23022
Train_df size 178352
Test_df size 22274
Index(['subject_id', 'Path', 'Sex', 'Age', 'Frontal/Lateral', 'AP/PA',
       'No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly',
       'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia',
       'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other',
       'Fracture', 'Support Devices'],
      dtype='object')
Validation_df path 23022
Train_df path 178352
Epoch 0/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366]
  2%|▏         | 1/65 [1:10:04<74:44:58, 4204.67s/it]0
Validation_losses: [0.2789364755153656]
saving
Epoch 1/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555]
  3%|▎         | 2/65 [2:28:04<76:04:37, 4347.26s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515]
saving
Epoch 2/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223]
  5%|▍         | 3/65 [3:45:21<76:21:51, 4434.05s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016]
saving
Epoch 3/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164]
  6%|▌         | 4/65 [5:13:07<79:21:49, 4683.77s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177]
saving
Epoch 4/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164, 0.26079076528549194]
  8%|▊         | 5/65 [6:47:13<82:52:27, 4972.46s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177, 0.26852133870124817]
saving
Epoch 5/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164, 0.26079076528549194, 0.2571488618850708]
  9%|▉         | 6/65 [8:20:19<84:30:25, 5156.36s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177, 0.26852133870124817, 0.27309733629226685]
Epoch 6/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164, 0.26079076528549194, 0.2571488618850708, 0.2537190914154053]
 11%|█         | 7/65 [9:54:16<85:23:50, 5300.53s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177, 0.26852133870124817, 0.27309733629226685, 0.27044084668159485]
Epoch 7/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164, 0.26079076528549194, 0.2571488618850708, 0.2537190914154053, 0.2503564953804016]
 12%|█▏        | 8/65 [11:24:15<84:23:42, 5330.22s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177, 0.26852133870124817, 0.27309733629226685, 0.27044084668159485, 0.2707034647464752]
decay loss from 5e-05 to 2.5e-05 as not seeing improvement in val loss
created new optimizer with LR 2.5e-05
Epoch 8/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164, 0.26079076528549194, 0.2571488618850708, 0.2537190914154053, 0.2503564953804016, 0.24165959656238556]
 14%|█▍        | 9/65 [12:45:35<80:48:41, 5195.03s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177, 0.26852133870124817, 0.27309733629226685, 0.27044084668159485, 0.2707034647464752, 0.2710981070995331]
decay loss from 2.5e-05 to 1.25e-05 as not seeing improvement in val loss
created new optimizer with LR 1.25e-05
Epoch 9/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164, 0.26079076528549194, 0.2571488618850708, 0.2537190914154053, 0.2503564953804016, 0.24165959656238556, 0.23463259637355804]
 15%|█▌        | 10/65 [14:07:38<78:07:29, 5113.63s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177, 0.26852133870124817, 0.27309733629226685, 0.27044084668159485, 0.2707034647464752, 0.2710981070995331, 0.2717791199684143]
decay loss from 1.25e-05 to 6.25e-06 as not seeing improvement in val loss
created new optimizer with LR 6.25e-06
Epoch 10/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164, 0.26079076528549194, 0.2571488618850708, 0.2537190914154053, 0.2503564953804016, 0.24165959656238556, 0.23463259637355804, 0.23019935190677643]
 17%|█▋        | 11/65 [15:29:39<75:50:09, 5055.72s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177, 0.26852133870124817, 0.27309733629226685, 0.27044084668159485, 0.2707034647464752, 0.2710981070995331, 0.2717791199684143, 0.273396760225296]
decay loss from 6.25e-06 to 3.125e-06 as not seeing improvement in val loss
created new optimizer with LR 3.125e-06
Epoch 11/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164, 0.26079076528549194, 0.2571488618850708, 0.2537190914154053, 0.2503564953804016, 0.24165959656238556, 0.23463259637355804, 0.23019935190677643, 0.22809003293514252]
 18%|█▊        | 12/65 [16:51:29<73:47:08, 5011.87s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177, 0.26852133870124817, 0.27309733629226685, 0.27044084668159485, 0.2707034647464752, 0.2710981070995331, 0.2717791199684143, 0.273396760225296, 0.2737545371055603]
decay loss from 3.125e-06 to 1.5625e-06 as not seeing improvement in val loss
created new optimizer with LR 1.5625e-06
Epoch 12/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164, 0.26079076528549194, 0.2571488618850708, 0.2537190914154053, 0.2503564953804016, 0.24165959656238556, 0.23463259637355804, 0.23019935190677643, 0.22809003293514252, 0.22662101686000824]
 20%|██        | 13/65 [18:12:59<71:52:06, 4975.51s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177, 0.26852133870124817, 0.27309733629226685, 0.27044084668159485, 0.2707034647464752, 0.2710981070995331, 0.2717791199684143, 0.273396760225296, 0.2737545371055603, 0.27383312582969666]
decay loss from 1.5625e-06 to 7.8125e-07 as not seeing improvement in val loss
created new optimizer with LR 7.8125e-07
Epoch 13/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164, 0.26079076528549194, 0.2571488618850708, 0.2537190914154053, 0.2503564953804016, 0.24165959656238556, 0.23463259637355804, 0.23019935190677643, 0.22809003293514252, 0.22662101686000824, 0.22613169252872467]
 22%|██▏       | 14/65 [19:34:47<70:12:00, 4955.31s/it]0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177, 0.26852133870124817, 0.27309733629226685, 0.27044084668159485, 0.2707034647464752, 0.2710981070995331, 0.2717791199684143, 0.273396760225296, 0.2737545371055603, 0.27383312582969666, 0.27392661571502686]
decay loss from 7.8125e-07 to 3.90625e-07 as not seeing improvement in val loss
created new optimizer with LR 3.90625e-07
Epoch 14/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.29504960775375366, 0.2747562527656555, 0.268869012594223, 0.26437997817993164, 0.26079076528549194, 0.2571488618850708, 0.2537190914154053, 0.2503564953804016, 0.24165959656238556, 0.23463259637355804, 0.23019935190677643, 0.22809003293514252, 0.22662101686000824, 0.22613169252872467, 0.22591431438922882]
0
Validation_losses: [0.2789364755153656, 0.27411481738090515, 0.27051904797554016, 0.26930123567581177, 0.26852133870124817, 0.27309733629226685, 0.27044084668159485, 0.2707034647464752, 0.2710981070995331, 0.2717791199684143, 0.273396760225296, 0.2737545371055603, 0.27383312582969666, 0.27392661571502686, 0.27456703782081604]
decay loss from 3.90625e-07 to 1.953125e-07 as not seeing improvement in val loss
created new optimizer with LR 1.953125e-07
no improvement in 10 epochs, break
Training complete in 1256m 35s
saving
4
batch_size 48

