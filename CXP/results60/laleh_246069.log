Wed Nov 27 13:11:29 EST 2019
guppy11
/h/laleh/PycharmProjects/Fairness/Nov28/CXP/23
  0%|          | 0/65 [00:00<?, ?it/s]Validation_df size: 23022
Train_df size 178352
Test_df size 22274
Index(['subject_id', 'Path', 'Sex', 'Age', 'Frontal/Lateral', 'AP/PA',
       'No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly',
       'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia',
       'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other',
       'Fracture', 'Support Devices'],
      dtype='object')
Validation_df path 23022
Train_df path 178352
Epoch 0/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362]
  2%|▏         | 1/65 [1:08:00<72:32:11, 4080.19s/it]0
Validation_losses: [0.2785782217979431]
saving
Epoch 1/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835]
  3%|▎         | 2/65 [2:14:55<71:03:54, 4060.86s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974]
saving
Epoch 2/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376]
  5%|▍         | 3/65 [3:20:51<69:23:25, 4029.12s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646]
Epoch 3/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523]
  6%|▌         | 4/65 [4:27:29<68:07:03, 4020.05s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225]
saving
Epoch 4/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375]
  8%|▊         | 5/65 [5:34:45<67:04:35, 4024.60s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875]
saving
Epoch 5/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375, 0.2568923234939575]
  9%|▉         | 6/65 [6:41:41<65:55:07, 4022.15s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875, 0.26731130480766296]
saving
Epoch 6/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375, 0.2568923234939575, 0.2533475458621979]
 11%|█         | 7/65 [7:54:50<66:34:23, 4132.13s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875, 0.26731130480766296, 0.2729238271713257]
Epoch 7/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375, 0.2568923234939575, 0.2533475458621979, 0.24997003376483917]
 12%|█▏        | 8/65 [9:06:50<66:19:08, 4188.58s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875, 0.26731130480766296, 0.2729238271713257, 0.27236104011535645]
Epoch 8/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375, 0.2568923234939575, 0.2533475458621979, 0.24997003376483917, 0.24632468819618225]
 14%|█▍        | 9/65 [10:14:32<64:33:53, 4150.61s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875, 0.26731130480766296, 0.2729238271713257, 0.27236104011535645, 0.2713167369365692]
decay loss from 5e-05 to 2.5e-05 as not seeing improvement in val loss
created new optimizer with LR 2.5e-05
Epoch 9/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375, 0.2568923234939575, 0.2533475458621979, 0.24997003376483917, 0.24632468819618225, 0.23692525923252106]
 15%|█▌        | 10/65 [11:24:10<63:32:11, 4158.76s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875, 0.26731130480766296, 0.2729238271713257, 0.27236104011535645, 0.2713167369365692, 0.27263617515563965]
decay loss from 2.5e-05 to 1.25e-05 as not seeing improvement in val loss
created new optimizer with LR 1.25e-05
Epoch 10/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375, 0.2568923234939575, 0.2533475458621979, 0.24997003376483917, 0.24632468819618225, 0.23692525923252106, 0.2295685112476349]
 17%|█▋        | 11/65 [12:33:43<62:26:46, 4163.08s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875, 0.26731130480766296, 0.2729238271713257, 0.27236104011535645, 0.2713167369365692, 0.27263617515563965, 0.2746531069278717]
decay loss from 1.25e-05 to 6.25e-06 as not seeing improvement in val loss
created new optimizer with LR 6.25e-06
Epoch 11/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375, 0.2568923234939575, 0.2533475458621979, 0.24997003376483917, 0.24632468819618225, 0.23692525923252106, 0.2295685112476349, 0.2249031513929367]
 18%|█▊        | 12/65 [13:42:25<61:06:35, 4150.86s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875, 0.26731130480766296, 0.2729238271713257, 0.27236104011535645, 0.2713167369365692, 0.27263617515563965, 0.2746531069278717, 0.27591684460639954]
decay loss from 6.25e-06 to 3.125e-06 as not seeing improvement in val loss
created new optimizer with LR 3.125e-06
Epoch 12/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375, 0.2568923234939575, 0.2533475458621979, 0.24997003376483917, 0.24632468819618225, 0.23692525923252106, 0.2295685112476349, 0.2249031513929367, 0.22262968122959137]
 20%|██        | 13/65 [14:54:05<60:36:05, 4195.49s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875, 0.26731130480766296, 0.2729238271713257, 0.27236104011535645, 0.2713167369365692, 0.27263617515563965, 0.2746531069278717, 0.27591684460639954, 0.27720534801483154]
decay loss from 3.125e-06 to 1.5625e-06 as not seeing improvement in val loss
created new optimizer with LR 1.5625e-06
Epoch 13/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375, 0.2568923234939575, 0.2533475458621979, 0.24997003376483917, 0.24632468819618225, 0.23692525923252106, 0.2295685112476349, 0.2249031513929367, 0.22262968122959137, 0.22110599279403687]
 22%|██▏       | 14/65 [16:07:10<60:14:35, 4252.45s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875, 0.26731130480766296, 0.2729238271713257, 0.27236104011535645, 0.2713167369365692, 0.27263617515563965, 0.2746531069278717, 0.27591684460639954, 0.27720534801483154, 0.2768283784389496]
decay loss from 1.5625e-06 to 7.8125e-07 as not seeing improvement in val loss
created new optimizer with LR 7.8125e-07
Epoch 14/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375, 0.2568923234939575, 0.2533475458621979, 0.24997003376483917, 0.24632468819618225, 0.23692525923252106, 0.2295685112476349, 0.2249031513929367, 0.22262968122959137, 0.22110599279403687, 0.22038434445858002]
 23%|██▎       | 15/65 [17:20:08<59:34:59, 4289.99s/it]0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875, 0.26731130480766296, 0.2729238271713257, 0.27236104011535645, 0.2713167369365692, 0.27263617515563965, 0.2746531069278717, 0.27591684460639954, 0.27720534801483154, 0.2768283784389496, 0.27724677324295044]
decay loss from 7.8125e-07 to 3.90625e-07 as not seeing improvement in val loss
created new optimizer with LR 3.90625e-07
Epoch 15/64
----------
0
24000
48000
72000
96000
120000
144000
168000
Train_losses: [0.2952585816383362, 0.27463409304618835, 0.2685294449329376, 0.26420852541923523, 0.2603587210178375, 0.2568923234939575, 0.2533475458621979, 0.24997003376483917, 0.24632468819618225, 0.23692525923252106, 0.2295685112476349, 0.2249031513929367, 0.22262968122959137, 0.22110599279403687, 0.22038434445858002, 0.21985675394535065]
0
Validation_losses: [0.2785782217979431, 0.27265340089797974, 0.27392274141311646, 0.26921287178993225, 0.2683563232421875, 0.26731130480766296, 0.2729238271713257, 0.27236104011535645, 0.2713167369365692, 0.27263617515563965, 0.2746531069278717, 0.27591684460639954, 0.27720534801483154, 0.2768283784389496, 0.27724677324295044, 0.2773754894733429]
decay loss from 3.90625e-07 to 1.953125e-07 as not seeing improvement in val loss
created new optimizer with LR 1.953125e-07
no improvement in 10 epochs, break
Training complete in 1113m 3s
saving
5
batch_size 48

